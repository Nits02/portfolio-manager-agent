{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2542360-bebd-477e-b857-d7ba6fcff6e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Portfolio Predictive Modeling\n",
    "\n",
    "This notebook demonstrates end-to-end predictive modeling for portfolio price direction prediction using AAPL and MSFT stocks.\n",
    "\n",
    "## Objectives\n",
    "1. Import and initialize the PredictiveModelAgent\n",
    "2. Train a binary classification model on AAPL and MSFT features\n",
    "3. Evaluate model performance with comprehensive metrics\n",
    "4. Register the trained model in Unity Catalog\n",
    "5. Display performance visualizations and insights\n",
    "\n",
    "## Prerequisites\n",
    "- Feature engineering must be completed (run `03_feature_engineering.ipynb`)\n",
    "- Unity Catalog must be configured with appropriate permissions\n",
    "- MLflow tracking must be enabled in the Databricks workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fc60928-00d1-49d5-8512-da0599d9e416",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Add src to path for imports\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import our custom agent\n",
    "from agents.predictive_model_agent import PredictiveModelAgent, PredictiveModelError\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Notebook executed at: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "46b9a67a-8c4f-4743-8ac8-64bf5ecd444b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Configuration and Setup\n",
    "\n",
    "Configure the predictive modeling environment for our specific use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff06e758-e8ae-4c96-82db-10cd9ade2593",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CATALOG_NAME = \"finance_catalog\"\n",
    "SCHEMA_NAME = \"silver\"\n",
    "TARGET_TICKERS = ['AAPL', 'MSFT']\n",
    "MODEL_NAME = \"portfolio_price_predictor_aapl_msft\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PREDICTIVE MODELING CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Unity Catalog: {CATALOG_NAME}\")\n",
    "print(f\"Schema: {SCHEMA_NAME}\")\n",
    "print(f\"Target Tickers: {', '.join(TARGET_TICKERS)}\")\n",
    "print(f\"Model Name: {MODEL_NAME}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3548b77d-af74-43a4-9fae-ed254f15f102",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Initialize Predictive Model Agent\n",
    "\n",
    "Create and configure the PredictiveModelAgent with our Unity Catalog settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3ebb51f-1ca5-4404-b87f-41e886075ef5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the Predictive Model Agent\n",
    "try:\n",
    "    agent = PredictiveModelAgent(\n",
    "        catalog=CATALOG_NAME,\n",
    "        schema=SCHEMA_NAME\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ PredictiveModelAgent initialized successfully!\")\n",
    "    print(f\"üìä Spark Session: {type(agent.spark).__name__}\")\n",
    "    print(f\"üìà MLflow Client: {type(agent.mlflow_client).__name__ if agent.mlflow_client else 'Not initialized'}\")\n",
    "    print(f\"üéØ Feature Columns: {agent.feature_cols}\")\n",
    "    print(f\"üè∑Ô∏è  Label Column: {agent.label_col}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to initialize PredictiveModelAgent: {str(e)}\")\n",
    "    print(\"Please ensure Spark is properly configured and accessible.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e9bfd11d-e601-410d-a9e4-4b62c1be9ef6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Data Verification\n",
    "\n",
    "Before training, let's verify that the required feature tables exist and contain data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64d59f3d-0faa-49eb-9073-b15d2dacaf22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Verify feature tables exist\n",
    "print(\"üîç Verifying feature tables...\")\n",
    "print()\n",
    "\n",
    "table_status = {}\n",
    "for ticker in TARGET_TICKERS:\n",
    "    table_name = f\"{CATALOG_NAME}.{SCHEMA_NAME}.features_{ticker}\"\n",
    "    try:\n",
    "        exists = agent.spark.catalog.tableExists(table_name)\n",
    "        table_status[ticker] = exists\n",
    "        \n",
    "        if exists:\n",
    "            # Get row count\n",
    "            row_count = agent.spark.table(table_name).count()\n",
    "            print(f\"‚úÖ {ticker}: Table exists with {row_count:,} rows\")\n",
    "        else:\n",
    "            print(f\"‚ùå {ticker}: Table {table_name} does not exist\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  {ticker}: Error checking table - {str(e)}\")\n",
    "        table_status[ticker] = False\n",
    "\n",
    "# Check if we can proceed\n",
    "available_tickers = [ticker for ticker, exists in table_status.items() if exists]\n",
    "print(f\"\\nüìã Available tickers for training: {available_tickers}\")\n",
    "\n",
    "if len(available_tickers) == 0:\n",
    "    print(\"‚ö†Ô∏è  No feature tables available. Please run feature engineering first.\")\n",
    "elif len(available_tickers) < len(TARGET_TICKERS):\n",
    "    print(f\"‚ö†Ô∏è  Only {len(available_tickers)}/{len(TARGET_TICKERS)} tables available.\")\n",
    "    print(\"Proceeding with available tickers.\")\n",
    "    TARGET_TICKERS = available_tickers\n",
    "else:\n",
    "    print(\"‚úÖ All required feature tables are available!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d338e08-1407-408e-9593-141d2674098e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Model Training\n",
    "\n",
    "Train the predictive model using the available feature data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d82012c5-13c5-4207-9afb-e85fbaf678ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Train the predictive model\n",
    "if len(TARGET_TICKERS) > 0:\n",
    "    print(f\"üöÄ Starting model training for: {', '.join(TARGET_TICKERS)}\")\n",
    "    print(f\"‚è∞ Training started at: {datetime.now()}\")\n",
    "    print()\n",
    "    \n",
    "    try:\n",
    "        # Train with hyperparameter tuning for better performance\n",
    "        training_results = agent.train(\n",
    "            tickers=TARGET_TICKERS,\n",
    "            hyperparameter_tuning=True\n",
    "        )\n",
    "        \n",
    "        print(\"üéâ Model training completed successfully!\")\n",
    "        print(f\"‚è∞ Training finished at: {datetime.now()}\")\n",
    "        print()\n",
    "        \n",
    "        # Store results for later use\n",
    "        model = training_results['model']\n",
    "        metrics = training_results['metrics']\n",
    "        feature_importance = training_results.get('feature_importance', [])\n",
    "        \n",
    "        print(\"üìä Training Results Summary:\")\n",
    "        print(\"-\" * 40)\n",
    "        for metric_name, value in metrics.items():\n",
    "            print(f\"{metric_name:20}: {value:.4f}\")\n",
    "        \n",
    "    except PredictiveModelError as e:\n",
    "        print(f\"‚ùå Training failed with PredictiveModelError: {str(e)}\")\n",
    "        model = None\n",
    "        metrics = None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Training failed with unexpected error: {str(e)}\")\n",
    "        model = None\n",
    "        metrics = None\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No tickers available for training. Skipping model training.\")\n",
    "    model = None\n",
    "    metrics = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e4e680d-352d-44b1-b7da-070904653fd4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Performance Evaluation\n",
    "\n",
    "Detailed analysis of model performance with visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f71b705f-f7ec-4a73-af17-c1da0ffa045e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Performance evaluation and visualization\n",
    "if metrics is not None:\n",
    "    print(\"üìà DETAILED PERFORMANCE ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Create performance visualization\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. Training vs Test Performance Comparison\n",
    "    train_metrics = ['train_auc', 'train_accuracy', 'train_f1']\n",
    "    test_metrics = ['test_auc', 'test_accuracy', 'test_f1']\n",
    "    \n",
    "    train_values = [metrics.get(m, 0) for m in train_metrics]\n",
    "    test_values = [metrics.get(m, 0) for m in test_metrics]\n",
    "    metric_names = ['AUC', 'Accuracy', 'F1-Score']\n",
    "    \n",
    "    x = range(len(metric_names))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax1.bar([i - width/2 for i in x], train_values, width, label='Training', alpha=0.8)\n",
    "    ax1.bar([i + width/2 for i in x], test_values, width, label='Test', alpha=0.8)\n",
    "    ax1.set_xlabel('Metrics')\n",
    "    ax1.set_ylabel('Score')\n",
    "    ax1.set_title('Training vs Test Performance')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(metric_names)\n",
    "    ax1.legend()\n",
    "    ax1.set_ylim(0, 1)\n",
    "    \n",
    "    # 2. All Metrics Overview\n",
    "    all_metrics = list(metrics.keys())\n",
    "    all_values = list(metrics.values())\n",
    "    \n",
    "    colors = ['skyblue' if 'train' in m else 'lightcoral' for m in all_metrics]\n",
    "    bars = ax2.barh(all_metrics, all_values, color=colors, alpha=0.7)\n",
    "    ax2.set_xlabel('Score')\n",
    "    ax2.set_title('All Performance Metrics')\n",
    "    ax2.set_xlim(0, 1)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, value in zip(bars, all_values):\n",
    "        ax2.text(value + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "                f'{value:.3f}', va='center', fontsize=8)\n",
    "    \n",
    "    # 3. Feature Importance (if available)\n",
    "    if feature_importance and len(feature_importance) > 0:\n",
    "        features = [f['feature'] for f in feature_importance[:8]]  # Top 8 features\n",
    "        importances = [f['importance'] for f in feature_importance[:8]]\n",
    "        \n",
    "        ax3.barh(features, importances, color='lightgreen', alpha=0.7)\n",
    "        ax3.set_xlabel('Importance')\n",
    "        ax3.set_title('Top Feature Importances')\n",
    "        \n",
    "        # Add value labels\n",
    "        for i, (feature, importance) in enumerate(zip(features, importances)):\n",
    "            ax3.text(importance + 0.001, i, f'{importance:.3f}', \n",
    "                    va='center', fontsize=8)\n",
    "    else:\n",
    "        ax3.text(0.5, 0.5, 'Feature importance\\nnot available', \n",
    "                ha='center', va='center', transform=ax3.transAxes)\n",
    "        ax3.set_title('Feature Importance (N/A)')\n",
    "    \n",
    "    # 4. Model Quality Assessment\n",
    "    quality_metrics = {\n",
    "        'Overfitting Risk': abs(metrics.get('train_auc', 0) - metrics.get('test_auc', 0)),\n",
    "        'Prediction Quality': metrics.get('test_auc', 0),\n",
    "        'Accuracy': metrics.get('test_accuracy', 0),\n",
    "        'Precision': metrics.get('test_precision', 0)\n",
    "    }\n",
    "    \n",
    "    # Create radar-like visualization\n",
    "    quality_names = list(quality_metrics.keys())\n",
    "    quality_values = list(quality_metrics.values())\n",
    "    \n",
    "    # Invert overfitting risk (lower is better)\n",
    "    quality_values[0] = 1 - min(quality_values[0], 1.0)\n",
    "    \n",
    "    ax4.pie(quality_values, labels=quality_names, autopct='%1.3f', startangle=90)\n",
    "    ax4.set_title('Model Quality Assessment')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed metrics\n",
    "    print(\"\\nüìä DETAILED METRICS:\")\n",
    "    print(\"-\" * 30)\n",
    "    for metric, value in metrics.items():\n",
    "        category = \"Training\" if \"train\" in metric else \"Test\"\n",
    "        metric_clean = metric.replace(\"train_\", \"\").replace(\"test_\", \"\").upper()\n",
    "        print(f\"{category:10} {metric_clean:10}: {value:.4f}\")\n",
    "    \n",
    "    # Model quality assessment\n",
    "    test_auc = metrics.get('test_auc', 0)\n",
    "    overfitting = abs(metrics.get('train_auc', 0) - test_auc)\n",
    "    \n",
    "    print(\"\\nüéØ MODEL QUALITY ASSESSMENT:\")\n",
    "    print(\"-\" * 30)\n",
    "    if test_auc >= 0.8:\n",
    "        print(\"‚úÖ Excellent prediction quality (AUC ‚â• 0.8)\")\n",
    "    elif test_auc >= 0.7:\n",
    "        print(\"‚úÖ Good prediction quality (AUC ‚â• 0.7)\")\n",
    "    elif test_auc >= 0.6:\n",
    "        print(\"‚ö†Ô∏è  Moderate prediction quality (AUC ‚â• 0.6)\")\n",
    "    else:\n",
    "        print(\"‚ùå Poor prediction quality (AUC < 0.6)\")\n",
    "    \n",
    "    if overfitting <= 0.05:\n",
    "        print(\"‚úÖ Low overfitting risk (< 5% gap)\")\n",
    "    elif overfitting <= 0.1:\n",
    "        print(\"‚ö†Ô∏è  Moderate overfitting risk (5-10% gap)\")\n",
    "    else:\n",
    "        print(\"‚ùå High overfitting risk (> 10% gap)\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No metrics available to display.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7f13de42-aa16-4284-b947-9bd7e8576bff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Model Registration\n",
    "\n",
    "Register the trained model in Unity Catalog for production use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d11fe0f-e0cd-48c4-ba20-b873d76f71a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Register the model in Unity Catalog\n",
    "if model is not None and metrics is not None:\n",
    "    print(\"üìù Registering model in Unity Catalog...\")\n",
    "    \n",
    "    try:\n",
    "        # Create comprehensive model description\n",
    "        model_description = f\"\"\"\n",
    "        Portfolio Price Direction Predictor\n",
    "        \n",
    "        Training Details:\n",
    "        - Tickers: {', '.join(TARGET_TICKERS)}\n",
    "        - Algorithm: Gradient Boosted Trees (GBT)\n",
    "        - Features: {', '.join(agent.feature_cols)}\n",
    "        - Training Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "        \n",
    "        Performance Metrics:\n",
    "        - Test AUC: {metrics.get('test_auc', 0):.4f}\n",
    "        - Test Accuracy: {metrics.get('test_accuracy', 0):.4f}\n",
    "        - Test F1-Score: {metrics.get('test_f1', 0):.4f}\n",
    "        \n",
    "        Model predicts next-day price direction (up=1, down=0) for portfolio optimization.\n",
    "        \"\"\".strip()\n",
    "        \n",
    "        registration_info = agent.register_model(\n",
    "            model_name=MODEL_NAME,\n",
    "            description=model_description\n",
    "        )\n",
    "        \n",
    "        print(\"üéâ Model registered successfully!\")\n",
    "        print()\n",
    "        print(\"üìã REGISTRATION DETAILS:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"Model Name: {registration_info['model_name']}\")\n",
    "        print(f\"Version: {registration_info['model_version']}\")\n",
    "        print(f\"URI: {registration_info['model_uri']}\")\n",
    "        print(f\"Registered: {registration_info['registration_time']}\")\n",
    "        \n",
    "        # Success summary\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üéä PREDICTIVE MODELING COMPLETED SUCCESSFULLY!\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"‚úÖ Model trained on {len(TARGET_TICKERS)} tickers: {', '.join(TARGET_TICKERS)}\")\n",
    "        print(f\"‚úÖ Performance: AUC = {metrics.get('test_auc', 0):.4f}, Accuracy = {metrics.get('test_accuracy', 0):.4f}\")\n",
    "        print(f\"‚úÖ Model registered: {MODEL_NAME} v{registration_info['model_version']}\")\n",
    "        print(f\"‚úÖ Ready for production deployment!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Model registration failed: {str(e)}\")\n",
    "        print(\"Model training was successful but registration encountered issues.\")\n",
    "        print(\"Please check Unity Catalog permissions and MLflow configuration.\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No model available for registration.\")\n",
    "    print(\"Please ensure model training completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15284634-f543-43d2-9897-de59cd534932",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Next Steps and Production Deployment\n",
    "\n",
    "Guidelines for using the trained model in production environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6ee1b07-b9e8-40ba-a530-e874220f6ba0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Display next steps and production guidance\n",
    "print(\"üöÄ NEXT STEPS FOR PRODUCTION DEPLOYMENT\")\n",
    "print(\"=\" * 50)\n",
    "print()\n",
    "\n",
    "if model is not None:\n",
    "    print(\"‚úÖ Model Training: COMPLETED\")\n",
    "    print(\"‚úÖ Performance Evaluation: COMPLETED\")\n",
    "    print(\"‚úÖ Model Registration: COMPLETED\")\n",
    "    print()\n",
    "    print(\"üìã PRODUCTION CHECKLIST:\")\n",
    "    print(\"1. üîç Review model performance metrics above\")\n",
    "    print(\"2. üß™ Test model predictions on recent data\")\n",
    "    print(\"3. üîí Set up model monitoring and alerts\")\n",
    "    print(\"4. üìä Configure automated retraining schedule\")\n",
    "    print(\"5. üöÄ Deploy model to production serving infrastructure\")\n",
    "    print()\n",
    "    print(\"üí° MODEL USAGE EXAMPLE:\")\n",
    "    print(f\"   model_uri = '{registration_info.get('model_uri', 'models:/' + MODEL_NAME + '/latest')}'\")\n",
    "    print(\"   model = mlflow.spark.load_model(model_uri)\")\n",
    "    print(\"   predictions = model.transform(feature_data)\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Model Training: FAILED\")\n",
    "    print(\"‚ùå Performance Evaluation: SKIPPED\")\n",
    "    print(\"‚ùå Model Registration: SKIPPED\")\n",
    "    print()\n",
    "    print(\"üîß TROUBLESHOOTING STEPS:\")\n",
    "    print(\"1. üìä Verify feature tables exist (run feature engineering)\")\n",
    "    print(\"2. üîå Check Spark and MLflow connectivity\")\n",
    "    print(\"3. üèóÔ∏è  Verify Unity Catalog permissions\")\n",
    "    print(\"4. üìù Review error messages above\")\n",
    "    print(\"5. üîÑ Re-run notebook after resolving issues\")\n",
    "\n",
    "print()\n",
    "print(\"üìö ADDITIONAL RESOURCES:\")\n",
    "print(\"- Model monitoring: Set up drift detection\")\n",
    "print(\"- A/B testing: Compare with existing models\")\n",
    "print(\"- Feature engineering: Continuously improve features\")\n",
    "print(\"- Performance tracking: Monitor real-world accuracy\")\n",
    "\n",
    "print(f\"\\n‚è∞ Notebook completed at: {datetime.now()}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "06_predictive_modeling",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
